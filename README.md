# TOXIC-COMMENTS-CLASSIFICATION
Developed a deep learning model using Long Short-Term Memory Networks (LSTM) to detect and classify toxic comments in natural language sentences. 
Implemented a filtering system to analyze and flag harmful words, preventing the posting of comments containing abusive or inappropriate language on online forums and social media platforms.
Successfully tested the model in a real-world application by integrating it into the Gradio app, providing a user-friendly interface to block such comment and enhancing online safety.
